{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e22d03b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7882\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7882/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "안녕하세요! 무엇을 도와드릴까요? 😊\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "def request_stt(audio_path):\n",
    "\n",
    "    endpoint = \"https://eastus.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1?language=ko-KR\"\n",
    "\n",
    "    headers={\n",
    "        \"Ocp-Apim-Subscription-Key\": \"2bwz5e594PSmSLbNdxvHmLvptmjIWfxdVtB12gnc1Y2HPomay4WXJQQJ99BFACYeBjFXJ3w3AAAYACOGQn2y\"\n",
    "    }\n",
    "\n",
    "    with open(audio_path, 'rb') as audio_file:\n",
    "        audio_data = audio_file.read()\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers, data=audio_data)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "\n",
    "    response_json = response.json()\n",
    "    content = response_json['DisplayText']\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "def request_tts(text):\n",
    "    endpoint = \"https://eastus.tts.speech.microsoft.com/cognitiveservices/v1\"\n",
    "\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": \"2bwz5e594PSmSLbNdxvHmLvptmjIWfxdVtB12gnc1Y2HPomay4WXJQQJ99BFACYeBjFXJ3w3AAAYACOGQn2y\",\n",
    "        \"Content-Type\": \"application/ssml+xml\",\n",
    "        \"X-Microsoft-OutputFormat\": \"riff-16khz-16bit-mono-pcm\"\n",
    "    }\n",
    "\n",
    "    body = f'''\n",
    "        <speak version='1.0' xml:lang='ko-KR'>\n",
    "            <voice xml:lang='ko-KR' xml:gender='Female' name='ko-KR-SunHiNeural'>\n",
    "                {text}\n",
    "            </voice>\n",
    "        </speak>\n",
    "    '''\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers, data=body)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    now = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    filename = f\"tts_result_{now}.wav\"\n",
    "\n",
    "    with open(filename, \"wb\") as audio_file:\n",
    "        audio_file.write(response.content)\n",
    "\n",
    "    return filename\n",
    "\n",
    "\n",
    "def request_gpt(text):\n",
    "    endpoint = \"https://fimtrus-ai-project-resource.cognitiveservices.azure.com/openai/deployments/fimtrus-gpt-41/chat/completions?api-version=2025-01-01-preview\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer 9VEZmMXEZd4aWzFIEVBKCse1NEa3en2LrD51oEyXbFc41XDbcP2VJQQJ99BFACYeBjFXJ3w3AAAAACOGydeD\"\n",
    "    }\n",
    "    \n",
    "    body = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            }\n",
    "        ],\n",
    "        \"max_completion_tokens\": 800,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 1,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"model\": \"fimtrus-gpt-41\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers, json=body)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    response_json = response.json()\n",
    "    content = response_json['choices'][0]['message']['content']\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    def change_audio(audio_path):\n",
    "        if audio_path is None:\n",
    "            return None\n",
    "        \n",
    "        content = request_stt(audio_path)\n",
    "        return content\n",
    "    \n",
    "    def click_send_tts(text):\n",
    "        filename = request_tts(text)\n",
    "        return filename\n",
    "    \n",
    "    def send_gpt(text, histories):\n",
    "        content = request_gpt(text)\n",
    "        print(histories)\n",
    "        print(content)\n",
    "        # 히스토리를 만들어서, 챗봇에 넣어주면 된다.\n",
    "        histories.append({\"role\": \"user\", \"content\": text})\n",
    "        histories.append({\"role\": \"assistant\", \"content\": content})\n",
    "        filename = request_tts(content)\n",
    "        return histories, filename\n",
    "\n",
    "    # Wrapper\n",
    "    with gr.Row():\n",
    "        # 좌측\n",
    "        with gr.Column(scale=3):\n",
    "            chatbot = gr.Chatbot(type=\"messages\")\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=3):\n",
    "                    prompt_textbox = gr.Textbox(label=\"메시지 입력\", placeholder=\"여기에 메시지를 입력하세요.\")\n",
    "                with gr.Column(scale=1):\n",
    "                    send_gpt_button = gr.Button(\"전송\")\n",
    "\n",
    "            gpt_audio = gr.Audio(label=\"GPT 음성 출력\", type=\"filepath\", interactive=False, autoplay=True)\n",
    "\n",
    "        # 우측 \n",
    "        with gr.Column(scale=1):\n",
    "            # STT\n",
    "            with gr.Column():\n",
    "                gr.Markdown('### STT')\n",
    "                input_audio = gr.Audio(sources=\"microphone\", type=\"filepath\", label=\"마이크 입력\")\n",
    "                output_text = gr.Textbox(label=\"음성 인식 결과\", placeholder=\"여기에 음성 인식 결과가 표시됩니다.\", interactive=False)\n",
    "\n",
    "        # TTS\n",
    "            with gr.Column():\n",
    "                gr.Markdown('### TTS')\n",
    "                tts_textbox = gr.Textbox(label=\"텍스트 입력\", placeholder=\"텍스트를 입력하세요.\")\n",
    "                send_tts_button = gr.Button(\"음성으로 변환\")\n",
    "                output_tts_audio = gr.Audio(label=\"음성 출력\", type=\"filepath\", interactive=False, autoplay=True)\n",
    "\n",
    "    input_audio.change(change_audio, inputs=[input_audio], outputs=[output_text])\n",
    "    send_tts_button.click(click_send_tts, inputs=[tts_textbox], outputs=[output_tts_audio])\n",
    "    send_gpt_button.click(send_gpt, inputs=[prompt_textbox, chatbot], outputs=[chatbot, gpt_audio])\n",
    "\n",
    "demo.launch()\n",
    "\n",
    "# request_gpt(\"안녕하세요\")\n",
    "# click_send_tts(\"안녕하세요, 음성 인식과 음성 합성 기능을 테스트합니다.\")\n",
    "\n",
    "# request_stt(\"C:/Users/USER/AppData/Local/Temp/gradio/a76805f2292f1cc7dedbbe5b3cd3ed89b007204a5429bb68d0ed9a788c79d945/audio.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
